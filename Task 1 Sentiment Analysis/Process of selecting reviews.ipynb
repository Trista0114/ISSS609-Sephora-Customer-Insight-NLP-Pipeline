{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Process of Selecting Reviews for Sentiment Analysis\n",
        "\n",
        "## Objective\n",
        "Sample 400 reviews per product from Sephora cosmetics dataset and split them into sentence-level data for text analytics.\n",
        "\n",
        "## Output Files\n",
        "1. `sampled_reviews_by_product_400_*.xlsx` - Review-level data (16,800 reviews)\n",
        "2. `sampled_400_sentence_level_*.xlsx` - Sentence-level data (~70,000 sentences)\n",
        "\n",
        "## Sampling Strategy\n",
        "- **Target**: 400 reviews per product, 42 products total\n",
        "- **Categories**: 3 (Cleansers, Moisturizers, Treatments)\n",
        "- **Brands**: Top 3 brands per category (9 brands total)\n",
        "- **Products**: Top 5 products per brand (ensuring 400+ reviews available)\n",
        "- **Balance**: Star ratings, recency, review length, quality\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration Parameters\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "from hashlib import sha1\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Paths\n",
        "DATA_PATH = \"Group project/Dataset for Group project/\"\n",
        "OUTPUT_DIR = \"/Users/dinghongyan/Downloads/Text Analytic\"\n",
        "\n",
        "# Sampling Configuration\n",
        "REVIEWS_PER_PRODUCT = 400\n",
        "REVIEWS_PER_STAR = 40\n",
        "MIN_REVIEW_CHARS = 20\n",
        "RECENT_PERCENTILE = 0.80\n",
        "LONG_REVIEW_PERCENTILE = 0.75\n",
        "\n",
        "# Target Categories\n",
        "TARGET_CATEGORIES = [\"Moisturizers\", \"Treatments\", \"Cleansers\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Initial Inspection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load product information\n",
        "product_file = os.path.join(DATA_PATH, \"product_info.csv\")\n",
        "df_product = pd.read_csv(product_file)\n",
        "\n",
        "# Load all review files\n",
        "review_files = sorted(glob.glob(os.path.join(DATA_PATH, \"reviews_*.csv\")))\n",
        "df_reviews = pd.concat([pd.read_csv(f) for f in review_files], ignore_index=True)\n",
        "\n",
        "print(f\"Total reviews loaded: {len(df_reviews):,}\")\n",
        "print(f\"Total products: {df_product['product_id'].nunique():,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "missing_summary = df_reviews.isnull().sum()\n",
        "missing_report = pd.DataFrame({\n",
        "    \"Missing Count\": missing_summary,\n",
        "    \"Missing Ratio (%)\": (missing_summary / len(df_reviews) * 100).round(2)\n",
        "})\n",
        "\n",
        "print(\"=== Missing Value Report ===\")\n",
        "print(missing_report)\n",
        "\n",
        "missing_cols = missing_report[missing_report[\"Missing Count\"] > 0]\n",
        "if not missing_cols.empty:\n",
        "    print(\"\\n⚠️ Columns with missing values:\")\n",
        "    print(missing_cols)\n",
        "else:\n",
        "    print(\"\\n✅ No missing values detected.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Merge Product Categories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Columns to merge from product_info\n",
        "TARGET_COLS = [\n",
        "    \"primary_category\", \"secondary_category\", \"tertiary_category\",\n",
        "    \"variation_type\", \"variation_value\", \"variation_desc\"\n",
        "]\n",
        "\n",
        "# Check if product_id is unique\n",
        "dup_in_product = df_product[\"product_id\"].duplicated(keep=False)\n",
        "if dup_in_product.any():\n",
        "    print(f\"⚠️ Warning: {dup_in_product.sum()} duplicate product_ids in product_info\")\n",
        "else:\n",
        "    print(\"✅ product_id is unique in product_info\")\n",
        "\n",
        "# Select columns for merging\n",
        "cols_to_add = [c for c in TARGET_COLS if c in df_product.columns]\n",
        "product_info_sub = df_product[[\"product_id\"] + cols_to_add].copy()\n",
        "\n",
        "# Merge with reviews\n",
        "df_reviews = df_reviews.reset_index(drop=True).copy()\n",
        "df_merged = df_reviews.merge(product_info_sub, on=\"product_id\", how=\"left\")\n",
        "df_merged[\"review_seq_id\"] = (df_merged.index + 1).astype(\"int64\")\n",
        "\n",
        "print(f\"\\n✅ Merge completed!\")\n",
        "print(f\"Rows before merge: {len(df_reviews):,}\")\n",
        "print(f\"Rows after merge: {len(df_merged):,}\")\n",
        "print(f\"Columns added: {['review_seq_id'] + cols_to_add}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Exploratory Analysis - Category Distribution\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
